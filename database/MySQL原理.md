# MySQL原理

## 一.MySQL的逻辑体系架构

![image-20241003151034179](C:\Users\zcy\AppData\Roaming\Typora\typora-user-images\image-20241003151034179.png)

客户端层：是服务于C/S程序或者是这些程序所需要的 ：连接处理，身份验证，安全管理等

MySQL Server层：这是MySQL的核心部分。在 MySQL系统处理底层数据之前的所有工作都是在这一层完成的，包括权限判断，
SQL解析，行计划优化，各个存储引擎提供的功能都集中在这一层，如存储过程，触发器，视图等。

存储引擎层：是底层数据存取操作实现部分，由多种存储引擎共同组成，负责存储和获取所有存储在MySQL中的数据。服务层

通过存储引擎API与其交互，包含了很多底层的操作，比如取出有特定主键的行等。存储引擎不能解析SQL，互相之间也不能通信，

仅仅是简单的响应服务器的请求。



## 二.MySQL的执行过程

**MySQL整体的执行过程如下图所示：**

 

![img](https://img2020.cnblogs.com/blog/1066538/202010/1066538-20201016015745814-1815633939.png)

### 2.1:连接器

连接器的主要职责就是:

- ①负责与客户端的通信,是半双工模式,这就意味着某一固定时刻只能由客户端向服务器请求或者服务器向客户端发送数据,而不能同时进行,其中MySQL在与客户端连接TCP/IP的

- ②验证请求用户的账户和密码是否正确,如果账户和密码错误,会报错:Access denied for user 'root'@'localhost' (using password: YES)

- ③如果用户的账户和密码验证通过,会在mysql自带的权限表中查询当前用户的权限:

mysql中存在4个控制权限的表，`分别为user表，db表，tables_priv表，columns_priv表,`mysql权限表的验证过程为：

- 1:**User表**:存放用户账户信息以及全局级别（所有数据库）权限，决定了来自哪些主机的哪些用户可以访问数据库实例
   **Db表:**存放`数据库级别`的权限，决定了来自哪些主机的哪些用户可以访问此数据库 
   **Tables_priv**表：`存放表级别的权限`，决定了来自哪些主机的哪些用户可以访问数据库的这个表 
   **Columns_priv**表：`存放列级别的权限`，决定了来自哪些主机的哪些用户可以访问数据库表的这个字段 
   **Procs_priv**表：`存放存储过程和函数`级别的权限

- 2:先从user表中的Host,User,Password这3个字段中判断连接的ip、用户名、密码是否存在，存在则通过验证。

- 3:通过身份认证后，进行权限分配，按照user，db，tables_priv，columns_priv的顺序进行验证。即先检查全局权限表user，如果user中对应的权限为Y，则此用户对所有数据库的权限都为Y，将不再检查db,  tables_priv,columns_priv；如果为N，则到db表中检查此用户对应的具体数据库，并得到db中为Y的权限；如果db中为N，则检查tables_priv中此数据库对应的具体表，取得表中的权限Y，以此类推

- 4:如果在任何一个过程中权限验证不通过,都会报错

### 2.2:缓存

   mysql的缓存主要的作用是为了提升查询的效率，缓存以key和value的哈希表形式存储，key是具体的sql语句，value是结果的集合。如果无法命中缓存,就继续走到分析器的的一步,如果命中缓存就直接返回给客户端  。不过需要注意的是在mysql的8.0版本以后，缓存被官方删除掉了。之所以删除掉,是因为查询缓存的失效非常频繁,如果在一个写多读少的环境中,缓存会频繁的新增和失效。对于某些更新压力大的数据库来说，查询缓存的命中率会非常低,mysql为了维护缓存可能会出现一定的伸缩性的问题,目前在5.6的版本中已经默认关闭了，比较推荐的一种做法是将缓存放在客户端，性能大概会提升5倍左右

### 2.3:分析器

  分析器的主要作用是将客户端发过来的sql语句进行分析，这将包括预处理与解析过程，在这个阶段会解析sql语句的语义，并进行关键词和非关键词进行提取、解析，并组成一个解析树。具体的关键词包括不限定于以下：select/update/delete/or/in/where/group by/having/count/limit等.如果分析到语法错误，会直接给客户端抛出异常:ERROR:You have an error in your SQL syntax.

比如：select * from user where userId =1234;

在分析器中就通过语义规则器将select from  where这些关键词提取和匹配出来,mysql会自动判断关键词和非关键词，将用户的匹配字段和自定义语句识别出来。这个阶段也会做一些校验:比如校验当前数据库是否存在user表，同时假如User表中不存在userId这个字段同样会报错：**unknown column in field list.**

### 2.4:优化器

能够进入到优化器阶段表示sql是符合mysql的标准语义规则的并且可以执行的，此阶段主要是进行sql语句的优化，会根据执行计划进行最优的选择,匹配合适的索引,选择最佳的执行方案。比如一个典型的例子是这样的：

表T,对A、B、C列建立联合索引，在进行查询的时候，当sql查询到的结果是:select xx where B=x and A=x and  C=x.很多人会以为是用不到索引的，但其实会用到,虽然索引必须符合最左原则才能使用,但是本质上,优化器会自动将这条sql优化为:where  A=x and B=x and  C=X,这种优化会为了底层能够匹配到索引，同时在这个阶段是自动按照执行计划进行预处理,mysql会计算各个执行方法的最佳时间,最终确定一条执行的sql交给最后的执行器

### 2.5:执行器

 在执行器的阶段,此时会调用存储引擎的API,API会调用存储引擎，主要有一下存储的引擎，不过常用的还是myisam和innodb:

![img](https://img2018.cnblogs.com/blog/1066538/201910/1066538-20191003214214106-920625231.png)

 

 引擎以前的名字叫做:**表处理器(**其实这个名字我觉得更能表达它存在的意义**)**负责对具体的数据文件进行操作,对sql的语义比如select或者update进行分析,执行具体的操作。在执行完以后会将具体的操作记录到binlog中,需要注意的一点是:select不会记录到binlog中,只有update/delete/insert才会记录到binlog中。而update会采用两阶段提交的方式,记录都redolog中



## 三.MySQL的执行顺序

事实上,sql并不是按照我们的书写顺序来从前往后、左往右依次执行的,它是按照固定的顺序解析的,主要的作用就是从上一个阶段的执行返回结果来提供给下一阶段使用，sql在执行的过程中会有不同的临时中间表，一般是按照如下顺序：

**![img](https://img2018.cnblogs.com/blog/1066538/201910/1066538-20191005155410162-1650888418.png)**

例子: select distinct s.id from T t  join S s on t.id=s.id where t.name="Yrion" group by t.mobile having  count(*)>2 order by s.create_time limit 5;

### 3.1：from

第一步就是选择出from关键词后面跟的表,这也是sql执行的第一步:表示要从数据库中执行哪张表。

实例说明:在这个例子中就是首先从数据库中找到表T

### 3.2:join on

join是表示要关联的表，on是连接的条件。通过from和join on选择出需要执行的数据库表T和S,产生笛卡尔积,生成T和S合并的临时中间表Temp1。on:确定表的绑定关系,通过on产生临时中间表Temp2.

实例说明：找到表S,生成临时中间表Temp1,然后找到表T的id和S的id相同的部分组成成表Temp2,Temp2里面包含着T和Sid相等的所有数据

### 3.3:where

where表示筛选,根据where后面的条件进行过滤,按照指定的字段的值(如果有and连接符会进行联合筛选)从临时中间表Temp2中筛选需要的数据,注意如果在此阶段找不到数据，会直接返回客户端,不会往下进行.这个过程会生成一个临时中间表Temp3。**注意在where中不可以使用聚合函数，聚合函数主要是(min\max\count\sum等函数)**

实例说明:在temp2临时表集合中找到T表的name="Yrion"的数据,找到数据后会成临时中间表Temp3,temp3里包含name列为"Yrion"的所有表数据

### 3.4:group by 

group by是进行分组，对where条件过滤后的临时表Temp3按照固定的字段进行分组,产生临时中间表Temp4，这个过程只是数据的顺序发生改变,而数据总量不会变化,表中的数据以组的形式存在

实例说明:在temp3表数据中对mobile进行分组,查找出mobile一样的数据,然后放到一起，产生temp4临时表。

### **3.5:Having**

对临时中间表Temp4进行聚合,这里可以为count等计数，然后产生中间表Temp5，在此阶段可以使用select中的别名

实例说明:在temp4临时表中找出条数大于2的数据,如果小于2直接被舍弃掉，然后生成临时中间表temp5

### 3.6:select

对分组聚合完的表挑选出需要查询的数据,如果为*会解析为所有数据,此时会产生中间表Temp6

实例说明：在此阶段就是对temp5临时聚合表中S表中的id进行筛选产生Temp6,此时temp6就只包含有s表的id列数据,并且name="Yrion"，通过mobile分组数量大于2的数据

### 3.7:Distinct

distinct对所有的数据进行去重,此时如果有min、max函数会执行字段函数计算，然后产生临时表Temp7

实例说明:此阶段对temp5中的数据进行去重,引擎API会调用去重函数进行数据的过滤,最终只保留id第一次出现的那条数据,然后产生临时中间表temp7

### 3.8:order by 

会根据Temp7进行顺序排列或者逆序排列，然后插入临时中间表Temp8，这个过程比较耗费资源

**实例说明：这段会将所有temp7临时表中的数据按照创建时间(create_time)进行排序,这个过程也不会有列或者行损失**

### **3.9:limit**

limit对中间表Temp8进行分页,产生临时中间表Temp9,返回给客户端。

**实例说明:在temp7中排好序的数据,然后取前五条插入到Temp9这个临时表中，最终返回给客户端**

**ps:实际上这个过程也并不是绝对这样的，中间mysql会有部分的优化以达到最佳的优化效果，比如在select筛选出找到的数据集**



## 四.MySQL的log

MySQL 日志 主要包括错误日志、查询日志、慢查询日志、事务日志、二进制日志几大类。其中，比较重要的还要属二进制日志 binlog（归档日志）和事务日志 redo log（重做日志）和 undo log（回滚日志）。
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/cd0926cae131edcad785c6229b15cc59.png#pic_center)

### redo log

redo log（重做日志）是InnoDB存储引擎独有的，它让MySQL拥有了崩溃恢复能力。

在 MySQL 里，如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程 IO 成本、查找成本都很高。 MySQL里使用 WAL 技术，WAL 的全称是 Write-Ahead Logging，它的关键点就是先写日志，再写磁盘。 具体来说，当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 redo log里面，并更新内存，这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做。 

InnoDB 的 redo log 是固定大小的，比如可以配置为一组 4 个文件，每个文件的大小是 1GB，那么总共就可以记录 4GB 的操作。从头开始写，写到末尾就又回到开头循环写。

有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为**crash-safe**。![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/0b22758c927270ea96c708ce8490f35c.png#pic_center)
刷盘时机依据innodb_flush_log_at_trx_commit 参数，设置为 0 的时候，表示每次事务提交时不进行刷盘操作，设置为 1 的时候，表示每次事务提交时都将进行刷盘操作（默认值)，设置为 2 的时候，表示每次事务提交时都只把 redo log buffer 内容写入 page cache，该值默认是1
另外，InnoDB 存储引擎有一个后台线程，每隔1 秒，就会**把 redo log buffer 中的内容写到文件系统缓存（page cache)，然后调用 fsync 刷盘**。也就是说，一个没有提交事务的 redo log 记录，也可能会刷盘。
除了后台线程每秒1次的轮询操作，还有一种情况，当 redo log buffer 占用的空间即将达到 innodb_log_buffer_size 一半的时候，后台线程会主动刷盘。

innodb_flush_log_at_trx_commit 为1时， 只要事务提交成功，redo log记录就一定在硬盘里，不会有任何数据丢失。如果事务执行期间MySQL挂了或宕机，这部分日志丢了，但是事务并没有提交，所以日志丢了也不会有损失。

硬盘上存储的 redo log 日志文件不只一个，而是以一个日志文件组的形式出现的，每个的redo日志文件大小都是一样的。在个日志文件组中还有两个重要的属性，分别是 write pos、checkpoint。write pos 是当前记录的位置，一边写一边后移，checkpoint 是当前要擦除的位置，也是往后推移

不每次把修改后的数据页直接刷盘而是使用relog的原因：
- 1.数据页大小是16KB，刷盘比较耗时，可能就修改了数据页里的几 Byte 数据，没有必要把完整的数据页刷盘
- 2.数据页刷盘是随机写，因为一个数据页对应的位置可能在硬盘文件的随机位置，所以性能是很差
- 3.如果是写 redo log，一行记录可能就占几十 Byte，只包含表空间号、数据页号、磁盘文件偏移 量、更新值，再加上是顺序写，所以刷盘速度很快。




### binlog 

binlog 是逻辑日志，记录内容是语句的原始逻辑，属于MySQL Server 层，binlog会记录所有涉及更新数据的逻辑操作，并且是顺序写。

binlog的写入时机也非常简单，事务执行过程中，先把日志写到binlog cache，事务提交的时候，再把binlog cache写到binlog文件中。
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/ade6adc98704d26f58d185380e08c262.png#pic_center)

数据恢复过程：

binlog会记录所有的逻辑操作，并且是采用“追加写”的形式。如果DBA承诺说半个月内可以恢复，那么备份系统中一定会保存最近半个月的所有binlog，同时系统会定期做整库备份。
这里的“定期”取决于系统的重要性，可以是一天一备，也可以是一周一备。当需要恢复到指定的某一秒时，比如某天下午两点发现中午十二点有一次误删表，需要找回数据，那你可以这么做：

- 首先，找到最近的一次全量备份，如果你运气好，可能就是昨天晚上的一个备份，从这个备份恢复到临时库；

- 然后，从备份的时间点开始，将备份的binlog依次取出来，重放到中午误删表之前的那个时刻。 这样你的临时库就跟误删之前的线上库一样了，然后你可以把表数据从临时库取出来，按需要恢复到线上库去。

### 两阶段提交

为了解决两份日志之间的逻辑一致问题(redo log在事务执行过程中可以不断写入，而binlog只有在提交事务时才写入，所以redo log与binlog的写入时机不一样)，InnoDB存储引擎使用两阶段提交方案。将redo log的写入拆成了两个步骤prepare和commit，这就是两阶段提交。
![在这里插入图片描述](https://i-blog.csdnimg.cn/blog_migrate/c0f94332a530f5cfb7d7a33fdbfef60a.png#pic_center)
使用两阶段提交后，写入binlog时发生异常也不会有影响，因为MySQL根据redo log日志恢复数据时，发现redo log还处于prepare阶段，并且没有对应binlog日志，就会回滚该事务。

为什么日志需要“两阶段提交”。这里不妨用反证法来进行解释。
由于redo log和binlog是两个独立的逻辑，如果不用两阶段提交，要么就是先写完redo log再写binlog，或者采用反过来的顺序。我们看看这两种方式会有什么问题。例子： UPDATE T set c=c+1 where ID = 2.

- 1.先写redo log后写binlog。假设在redo log写完，binlog还没有写完的时候，MySQL进程异常重启。由于我们前面说过的，redo  log写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行c的值是1。但是由于binlog没写完就crash了，这时候binlog里面就没有记录这个语句。因此，之后备份日志的时候，存起来的binlog里面就没有这条语句。然后你会发现，如果需要用这个binlog来恢复临时库的话，由于这个语句的binlog丢失，这个临时库就会少了这一次更新，恢复出来的这一行c的值就是0，与原库的值不同。 

- 2.先写binlog后写redo log。如果在binlog写完之后crash，由于redo log还没写，崩溃恢复以后这个事务无效，所以这一行c的值是0。但是binlog里面已经记录了“把c从0改成1”这个日志。所以，在之后用binlog来恢复的时候就多了一个事务出来，恢复出来的这一行c的值就是1，与原库的值不同。

可以看到，如果不使用“两阶段提交”，那么数据库的状态就有可能和用它的日志恢复出来的库的状态不一致。
你可能会说，这个概率是不是很低，平时也没有什么动不动就需要恢复临时库的场景呀？
其实不是的，不只是误操作后需要用这个过程来恢复数据。当你需要扩容的时候，也就是需要再多搭建一些备库来增加系统的读能力的时候，现在常见的做法也是用全量备份加上应用binlog来实现的，这个“不一致”就会导致你的线上出现主从数据库不一致的情况。简单说，redo log和binlog都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致。

### undo log

我们知道如果想要保证事务的原子性，就需要在异常发生时，对已经执行的操作进行回滚，在 MySQL 中，恢复机制是通过 回滚日志（undo log） 实现的，所有事务进行的修改都会先记录到这个回滚日志中，然后再执行相关的操作。如果执行过程中遇到异常的话，我们直接利用 回滚日志 中的信息将数据回滚到修改之前的样子即可！并且，回滚日志会先于数据持久化到磁盘上。这样就保证了即使遇到数据库突然宕机等情况，当用户再次启动数据库的时候，数据库还能够通过查询回滚日志来回滚将之前未完成的事务。 

另外，MVCC 的实现依赖于：隐藏字段、Read View、undo log。在内部实现中，InnoDB 通过数据行的 DB_TRX_ID 和 Read View 来判断数据的可见性，如不可见，则通过数据行的 DB_ROLL_PTR 找到 undo log 中的历史版本。每个事务读到的数据版本可能是不一样的，在同一个事务中，用户只能看到该事务创建 Read View 之前已经提交的修改和该事务本身做的修改



## 五.事务

事务指的是满足 ACID 特性的一组操作，可以通过 Commit 提交一个事务，也可以使用 Rollback 进行回滚。

### 1.ACID
1.原子性（A）：事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用。
2.一致性（C）：事务必须使数据库从一个一致性状态变换到另外一个一致性状态。
3.隔离性（I）：并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的。
4.持久性（D）：一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。

### 2.InnoDB引擎中事务的实现原理
MySQL InnoDB 引擎使用 **redo log**(重做日志) 保证事务的**持久性**，使用 **undo log**(回滚日志) 来保证事务的**原子性**。 MySQL InnoDB 引擎通过 **锁机制、MVCC **等手段来保证事务的**隔离性**（ 默认支持的隔离级别是**REPEATABLE-READ** ）。保证了事务的持久性、原子性、隔离性之后，一致性才能得到保障。
### 3.并发事务带来的问题
1.脏读（Dirty read）: 当一个事务正在访问数据并且对数据进行了修改，而这种修改还没有提交到数据库中，这时另外一个事务也访问了这个数据，然后使用了这个数据。因为这个数据是还没有提交的数据，那么另外一个事务读到的这个数据是“脏数据”，依据“脏数据”所做的操作可能是不正确的。 
2.丢失修改（Lost to modify）: 指在一个事务读取一个数据时，另外一个事务也访问了该数据，那么在第一个事务中修改了这个数据后，第二个事务也修改了这个数据。这样第一个事务内的修改结果就被丢失，因此称为丢失修改。 例如：事务 1 读取某表中的数据 A=20，事务 2 也读取 A=20，事务 1 修改 A=A-1，事务 2 也修改 A=A-1，最终结果 A=19，事务 1 的修改被丢失。 
3.不可重复读（Unrepeatable read）: 指在一个事务内多次读同一数据。在这个事务还没有结束时，另一个事务也访问该数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读取的数据可能不太一样。这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读。 
4.幻读（Phantom read）: 幻读与不可重复读类似。它发生在一个事务（T1）读取了几行数据，接着另一个并发事务（T2）插入了一些数据时。在随后的查询中，第一个事务（T1）就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。

### 4.事务隔离级别
**READ-UNCOMMITTED**(读取未提交)： 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。
**READ-COMMITTED**(读取已提交)： 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。 
**REPEATABLE-READ**(可重复读)： 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。 
**SERIALIZABLE**(可串行化)： 最高的隔离级别，完全服从 ACID 的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。

### 5.隔离级别与锁的关系

MySQL中锁的种类很多，有常见的表锁和行锁。 行锁则是锁住数据行，这种加锁方法比较复杂，但是由于只锁住有限的数据，对于其它数据不加限制，所以并发能力强，MySQL一般都是用行锁来处理并发事务。这里主要讨论的也就是行锁。

Read Uncommitted这种级别，数据库一般都不会用，而且任何操作都不会加锁，这里就不讨论了。 除非是记录日志的数据库。

在RC级别中，数据的读取都是不加锁的，但是数据的写入、修改和删除是需要加锁的。

如果两个事务都更新索引c=5的数据，后面那个事务会报Lock wait timeout exceeded; try restarting transaction。

这时我们要注意到，c是有索引的，如果是没有索引的d呢？update t set c=100 where d=5;
那么MySQL会给整张表的所有数据行的加行锁。这里听起来有点不可思议，但是当sql运行的过程中，MySQL并不知道哪些数据行是 d = 5 的（没有索引嘛），
如果一个条件无法通过索引快速过滤，存储引擎层面就会将所有记录加锁后返回，再由MySQL Server层进行过滤。
但在实际使用过程当中，MySQL做了一些改进，在MySQL Server过滤条件，发现不满足后，会调用unlock_row方法，把不满足条件的记录释放锁 (违背了二段锁协议的约束)。
这样做，保证了最后只会持有满足条件记录上的锁，但是每条记录的加锁操作还是不能省略的。可见即使是MySQL，为了效率也是会违反规范的。（参见《高性能MySQL》中文第三版p181）
这种情况同样适用于MySQL的默认隔离级别RR。所以对一个数据量很大的表做批量修改的时候，如果无法使用相应的索引，MySQL Server过滤数据的的时候特别慢，就会出现虽然没有修改某些行的数据，但是它们还是被锁住了的现象。

注：一次封锁 和 二段锁协议
一次封锁：一次封锁法要求事务必须一次对所有要使用到的数据项进行加锁，否则不能继续运行。 但是事务显然不能事先知道需要用到哪些数据，所以无法在一开始就将所有要使用到的数据进行加锁。
二段锁： 加锁阶段和解锁阶段，所有的加锁动作必须要解锁阶段之前进行。



#### MVCC

MVCC:多版本并发控制,通过数据行的多个版本管理来实现数据库的并发控制。

在 Repeatable Read 和 Read Committed 两个隔离级别下，如果是执行普通的 select 语句（不包括 select ... lock in share mode ,select ... for update）则会使用一致性非锁定读（MVCC）。并且在 Repeatable Read 下 MVCC 实现了可重复读和防止部分幻读。

如果读取的行正在执行 DELETE 或 UPDATE 操作，这时读取操作不会去等待行上锁的释放。相反地，InnoDB 存储引擎会去读取行的一个快照数据，对于这种读取历史数据的方式，我们叫它快照读 (snapshot read)。

如果执行的是下列语句，就是 锁定读（Locking Reads）在锁定读下，读取的是数据的最新版本，这种读也被称为 当前读（current read）。锁定读会对读取到的记录加锁。
- select ... lock in share mode
- select ... for update
- insert、update、delete 操作

在一致性非锁定读下，即使读取的记录已被其它事务加上 X 锁，这时记录也是可以被读取的，即读取的快照数据。上面说了，在 Repeatable Read 下 MVCC 防止了部分幻读，这边的 “部分” 是指在 一致性非锁定读 情况下，只能读取到第一次查询之前所插入的数据（根据 Read View 判断数据可见性，Read View 在第一次查询时生成）。但是！如果是 当前读 ，每次读取的都是最新数据，这时如果两次查询中间有其它事务插入数据，就会产生幻读。所以， InnoDB 在实现Repeatable Read 时，如果执行的是当前读，则会对读取的记录使用 Next-key Lock（临键锁(Next-Key Locks)，结合间隙锁与行锁，） ，来防止其它事务在间隙间插入数据。

![image-20241004154729360](C:\Users\zcy\AppData\Roaming\Typora\typora-user-images\image-20241004154729360.png)

在当前读下，读取的都是最新的数据，如果其它事务有插入新的记录，并且刚好在当前事务查询范围内，就会产生幻读！InnoDB 使用 Next-key Lock来防止这种情况。当执行当前读时，会锁定读取到的记录的同时，锁定它们的间隙，防止其它事务在查询范围内插入数据。只要我不让你插入，就不会发生幻读。

当然，即使使用了MVCC加有一种特殊的情况会发生幻读，即如下的例子。事务1先查询生成快照，在事务2修改数据后，分别进行快照读和当前读，读取到的数据是不一致的，发生了幻读。

![image-20241004155528729](C:\Users\zcy\AppData\Roaming\Typora\typora-user-images\image-20241004155528729.png)

所以如何避免幻读？

1.使用SERIALIZABLE级别；

2.在RR级别下，尽量使用快照读，需要使用当前读时，一定要在事务一开始就立即加锁，这样就会有Next-key Lock来防止幻读。

注：RC和RR下区别：

- 在 RC 隔离级别下的 每次select 查询前都生成一个Read View (m_ids 列表) 
- 在 RR 隔离级别下只在事务开始后 第一次select 数据前生成一个Read View（m_ids 列表）

##### InnoDB对MVCC的实现

MVCC 的实现依赖于：隐藏字段、Read View、undo log。在内部实现中，InnoDB 通过数据行的 DB_TRX_ID 和 Read View 来判断数据的可见性，如不可见，则通过数据行的 DB_ROLL_PTR 找到 undo log 中的历史版本。每个事务读到的数据版本可能是不一样的，在同一个事务中，用户只能看到该事务创建 Read View 之前已经提交的修改和该事务本身做的修改

在内部，InnoDB 存储引擎为每行数据添加了三个隐藏字段  (opens new window)： 
- DB_TRX_ID（6字节）：表示最后一次插入或更新该行的事务 id。此外，delete 操作在内部被视为更新，只不过会在记录头 Record header 中的 deleted_flag 字段将其标记为已删除
- DB_ROLL_PTR（7字节） 回滚指针，指向该行的 undo log 。如果该行未被更新，则为空 
- DB_ROW_ID（6字节）：如果没有设置主键且该表没有唯一非空索引时，InnoDB 会使用该 id 来生成聚簇索引

##### Read View

Read View  (opens new window) 主要是用来做可见性判断，里面保存了 “当前对本事务不可见的其他活跃事务” 
主要有以下字段：

- m_low_limit_id：目前出现过的最大的事务 ID+1，即下一个将被分配的事务 ID。大于等于这个 ID 的数据版本均不可见 
- m_up_limit_id：活跃事务列表 m_ids 中最小的事务 ID，如果 m_ids 为空，则 m_up_limit_id 为 m_low_limit_id。小于这个 ID 的数据版本均可见 
- m_ids：Read View 创建时其他未提交的活跃事务 ID 列表。创建 Read View时，将当前未提交事务 ID 记录下来，后续即使它们修改了记录行的值，对于当前事务也是不可见的。m_ids 不包括当前事务自己和已提交的事务（正在内存中） 
- m_creator_trx_id：创建该 Read View 的事务 ID

##### 数据可见性算法
在 InnoDB 存储引擎中，创建一个新事务后，执行每个 select 语句前，都会创建一个快照（Read View），快照中保存了当前数据库系统中正处于活跃（没有 commit）的事务的 ID 号。其实简单的说保存的是系统中当前不应该被本事务看到的其他事务 ID 列表（即 m_ids）。当用户在这个事务中要读取某个记录行的时候，InnoDB 会将该记录行的 DB_TRX_ID 与 Read View 中的一些变量及当前事务 ID 进行比较，判断是否满足可见性条件
- 1.如果记录 DB_TRX_ID < m_up_limit_id，那么表明最新修改该行的事务（DB_TRX_ID）在当前事务创建快照之前就提交了，所以该记录行的值对当前事务是可见的 
- 2.如果 DB_TRX_ID >= m_low_limit_id，那么表明最新修改该行的事务（DB_TRX_ID）在当前事务创建快照之后才修改该行，所以该记录行的值对当前事务不可见。跳到步骤 5 
- 3.m_ids 为空，则表明在当前事务创建快照之前，修改该行的事务就已经提交了，所以该记录行的值对当前事务是可见的 如果 m_up_limit_id <= DB_TRX_ID < m_low_limit_id，表明最新修改该行的事务（DB_TRX_ID）在当前事务创建快照的时候可能处于“活动状态”或者“已提交状态”；所以就要对活跃事务列表 m_ids 进行查找（源码中是用的二分查找，因为是有序的）
- 4.如果在活跃事务列表 m_ids 中能找到 DB_TRX_ID，表明：① 在当前事务创建快照前，该记录行的值被事务 ID 为 DB_TRX_ID 的事务修改了，但没有提交；或者 ② 在当前事务创建快照后，该记录行的值被事务 ID 为 DB_TRX_ID 的事务修改了。这些情况下，这个记录行的值对当前事务都是不可见的。跳到步骤 5 

	在活跃事务列表中找不到，则表明“id 为 trx_id 的事务”在修改“该记录行的值”后，在“当前事务”创建快照前就已经提交了，所以记录行对当前事务可见 
- 5.在该记录行的 DB_ROLL_PTR 指针所指向的 undo log 取出快照记录，用快照记录的 DB_TRX_ID 跳到步骤 1 重新开始判断，直到找到满足的快照版本或返回空



**举例**：MVCC下InnoDB的增删查改是怎么work的
1、插入数据（insert）:记录的版本号即当前事务的版本号
执行一条数据语句：insert into testmvcc values(1,"test");
假设事务id为1，那么插入后的数据行如下：

| id   | name | create_version | delete_version |
| ---- | ---- | -------------- | -------------- |
| 1    | test | 1              |                |

2、在更新操作的时候，采用的是先标记旧的那行记录为已删除，并且删除版本号是事务版本号，然后插入一行新的记录的方式。
比如，针对上面那行记录，事务Id为2 要把name字段更新
update table set name= 'new_value' where id=1;

| id   | name      | create_version | delete_version |
| ---- | --------- | -------------- | -------------- |
| 1    | test      | 1              | 2              |
| 1    | new_value | 2              |                |

3、删除操作的时候，就把事务版本号作为删除版本号。比如
delete from table where id=1;

| id   | name      | create_version | delete_version |
| ---- | --------- | -------------- | -------------- |
| 1    | new_value | 2              | 3              |

4、查询操作：
从上面的描述可以看到，在查询时要符合以下两个条件的记录才能被事务查询出来：

1) 删除版本号未指定或者大于当前事务版本号，即查询事务开启后确保读取的行未被删除。(即上述事务id为2的事务查询时，依然能读取到事务id为3所删除的数据行)
2) 创建版本号 小于或者等于 当前事务版本号 ，就是说记录创建是在当前事务中（等于的情况）或者在当前事务启动之前的其他事物进行的insert。（即事务id为2的事务只能读取到create version<=2的已提交的事务的数据集）

## 六.索引

http://note.moguit.cn/#/./%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL%E7%B4%A2%E5%BC%95/README
1.b树与b+树

详解：https://www.cnblogs.com/lianzhilei/p/11250589.html

为什么说B+树比B树更适合数据库索引？
1）B+树的磁盘读写代价更低
　　B+树的内部结点并没有指向关键字具体信息的指针。因此其内部结点相对B 树更小。如果把所有同一内部结点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多。一次性读入内存中的需要查找的关键字也就越多。相对来说IO读写次数也就降低了；

2）B+树查询效率更加稳定
　　由于非终结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。所以任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当；

3）B+树便于范围查询（最重要的原因，范围查找是数据库的常态）
　　B树在提高了IO性能的同时并没有解决元素遍历的效率低下的问题，正是为了解决这个问题，B+树应用而生。B+树只需要去遍历叶子节点就可以实现整棵树的遍历。而且在数据库中基于范围的查询是非常频繁的，而B树不支持这样的操作或者说效率太低
为啥用B+不用红黑树作索引？

这和索引的存储原理相关，页是InnoDB引擎管理数据库的最小磁盘单位（16KB），红黑树中一个父节点只有两个子节点，不能填满一个页上的内容，造成空间浪费，而B+树分支多，不浪费空间。而且，相同数量的内容，B+树更矮，代表磁盘IO次数更少，一次 IO耗时是毫秒级的。

所以红黑树和二叉树一般用在内存中，通常内存是纳秒级的
2.优缺点

优点：

    加快查询效率
    帮助服务器避免排序和临时表
    将IO变成顺序IO

缺点：建立和维护索引耗费时间空间，更新索引很慢。
3.索引失效的情况

    组合索引为使用最左前缀，例如组合索引（A，B），where B = b 不会使用索引
    like未使用最左前缀，where A like “%China”
    搜索一个索引而在另一个索引上做 order by， where A = a order by B，只会使用A上的索引，因为查询只使用一个索引。
    or会使索引失效。如果查询字段相同，也可以使用索引。例如 where A = a1 or A = a2（生效），where A=a or B = b （失效）
    在索引列上的操作（计算和函数都会导致失效），函数upper()等，or、！ = （<>）,not in 等

4.适合创建索引的地方

    某列经常作为最大最小值；
    经常被查询的字段；
    经常用作表连接的字段；
    经常出现在ORDER BY/GROUP BY/DISDINCT后面的字段

5.分类

    普通索引：普通索引的唯一作用就是为了快速查询数据，一张表允许创建多个普通索引，并允许数据重复和 NULL
    唯一索引 UNIQUE：索引列的值必须唯一，但允许有空值；
    主键索引 PRIMARY KEY：必须唯一，不允许空值（是一种特殊的唯一索引；MySQL创建主键时默认为聚集索引，但主键也可以是非聚集索引）；
    组合索引：在多个字段上创建索引，遵循最左匹配原则；一般情况下,将查询需求频繁或者字段选择性高的列放在前面。
    覆盖（Covering）索引：索引包含了所有满足查询所需要的数据，查询的时候只需要读取索引而不需要回表读取数据；
    非聚簇索引：其索引结构和数据分开存放。叶子节点的data域中存放数据的地址，根据key找到数据地址后，需要根据地址去读取相应的数据记录。辅助索引属于非聚簇索引。优点：更新代价较小，因为叶子节点不存放数据。缺点：需要回表（除非是覆盖索引）
    聚簇索引：其索引结构和数据一起存放。叶子节点的data域中存放完整的数据记录，key是主键（没有主键则用唯一索引作主键，再没有则生成rowid作主键）。 InnoDB其他索引都作为辅助索引，data域存放主键值；使用辅助索引查找时，先找到主键值，再走主键索引，找数据记录。主键索引属于聚簇索引。优点：查询快，不需要回表。缺点：如果索引无序插入的，会引起页分裂，降低性能；更新代价大，因为叶子节点存放数据。

6.索引的使用

MySQL每次只使用一个索引，与其说 数据库查询只能用一个索引，倒不如说，和全表扫描比起来，去分析两个索引 B+树更耗费时间，所以where A=a and B=b 这种查询使用（A，B）的组合索引最佳，B+树根据（A，B）来排序。

建立几个索引，就会生成几棵B+Tree，但是带有原始数据行的B+Tree只有一棵，是由主键索引生成的，叶子节点中存放的就是整张表的行记录数据，另外树上的叶子节点带的是主键值。普通索引是为了查找主键索引的二级索引，先找到主键索引然后再通过主键索引找数据，但是可能会存在回表的问题。
7.索引的创建

1.使用Alter Table语句创建索引

ALTER TABLE table_name ADD [UNIQUE | FULLTEXT | SPATIAL] [INDEX | KEY] [index_name] (col_name[length],...) [ASC | DESC]

    1

2.使用 CREATE INDEX语句创建索引

CREATE [UNIQUE | FULLTEXT | SPATIAL] INDEX index_name ON table_name (col_name[length],...) [ASC | DESC]

    1

3.创建表的时候创建索引

CREATE TABLE table_name [col_name data_type] [UNIQUE | FULLTEXT | SPATIAL] [INDEX | KEY] [index_name] (col_name [length]) [ASC | DESC]

    1

其中UNIQUE 、 FULLTEXT 和 SPATIAL 为可选参数，分别表示唯一索引、全文索引和空间索引；

设定为主键后数据库会自动建立索引，innodb为聚集索引。除PRIMARY索引以外的所有索引都称为非聚集索引或二级索引
8.自增主键和非自增主键

自增主键：自增ID是在设计表时将id字段的值设置为自增的形式，这样当插入一行数据时无需指定id会自动根据前一字段的ID值+1进行填充。在MySQL数据库中，可通过sql语句AUTO_INCREMENT来对特定的字段启用自增赋值 使用自增ID作为主键，能够保证字段的原子性.
优点：

    数据库自动编号，速度快，而且是增量增长，按顺序存放，对于检索非常有利；
    数字型，占用空间小，易排序，在程序中传递也方便；
    如果通过非系统增加记录时，可以不用指定该字段，不用担心主键重复问题。

缺点：因为自动增长，在手动要插入指定ID的记录时会显得麻烦，尤其是当系统与其它系统集成时，需要数据导入时，很难保证原系统的ID不发生主键冲突（前提是老系统也是数字型的）。特别是在新系统上线时，新旧系统并行存在，并且是异库异构的数据库的情况下，需要双向同步时，自增主键将是你的噩梦；

UUID含义是通用唯一识别码 (Universally Unique Identifier)，指在一台机器上生成的数字，它保证对在同一时空中的所有机器都是唯一的。通常平台会提供生成的API。换句话说能够在一定的范围内保证主键id的唯一性。

优点：出现数据拆分、合并存储的时候，能达到全局的唯一性
缺点：

    影响插入速度， 并且造成硬盘使用率低
    uuid之间比较大小相对数字慢不少， 影响查询速度。
    uuid占空间大， 如果你建的索引越多， 影响越严重

9.主键设置方法

http://c.biancheng.net/view/2440.html

